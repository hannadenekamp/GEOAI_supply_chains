{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_22940\\1728019391.py:11: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n",
      "c:\\Users\\hanna\\Anaconda3\\envs\\geothings\\Lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:38: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\hanna\\Anaconda3\\envs\\geothings\\Lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:164: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\hanna\\Anaconda3\\envs\\geothings\\Lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:198: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\hanna\\Anaconda3\\envs\\geothings\\Lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:260: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import rioxarray as rxr\n",
    "from rasterio.plot import plotting_extent\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries\n",
    "import osmnx as ox\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import shapely\n",
    "\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "\n",
    "from skimage.graph import route_through_array\n",
    "\n",
    "import networkx as nx\n",
    "import momepy\n",
    "\n",
    "import fiona\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from osgeo import  ogr, gdal, osr, os\n",
    "import numpy as np\n",
    "import itertools\n",
    "from math import sqrt,ceil\n",
    "from shapely.geometry import shape as shp\n",
    "\n",
    "import richdem as rd\n",
    "import folium\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from xrspatial import a_star_search\n",
    "from xrspatial.utils import get_dataarray_resolution\n",
    "\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "import geopandas as gpd\n",
    "\n",
    "import general_file_handling as gfh\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from xrspatial import slope, hillshade\n",
    "import xarray as xr\n",
    "\n",
    "import datashader as ds\n",
    "\n",
    "from datashader.transfer_functions import shade\n",
    "from datashader.transfer_functions import stack\n",
    "from datashader.transfer_functions import dynspread\n",
    "from datashader.transfer_functions import set_background\n",
    "from datashader.colors import Elevation\n",
    "import xrspatial\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_raster as pr\n",
    "import water_roads_graph as wrg\n",
    "import connecting_nodes as cn\n",
    "import graph_funcs as gf\n",
    "from tiler import Tiler, Merger\n",
    "from matplotlib import image as img\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "import validation as val\n",
    "# from json import Point, Feature, FeatureCollection, dump\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from shapely.geometry import box\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "from shapely import contains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of data\n",
    "pathname = '../Data/dem2/ASTGTMV003_N08W074'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_counter_l = 0\n",
    "graph_counter_s = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load large network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get geometry of entire area\n",
    "#add airstrips of entire area\n",
    "#connect water and road only at essential points - how?\n",
    "# or cut into really small pieces and then combine?? or add to large network immediately\n",
    "#simplification?\n",
    "#add dense network to small network\n",
    "# 12.533\n",
    "# -76.026 -65.391\n",
    "# 7.711\n",
    "\n",
    "#1211\n",
    "#8098\n",
    "#11170\n",
    "\n",
    "large_coords = [-76.026, 7.711, -65.391, 12.533]\n",
    "\n",
    "large_geom = gfh.create_geom(large_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =False\n",
    "#to test:\n",
    "if test == True:\n",
    "    dem_area, dem_array_area = gfh.read_rast_rasterio(pathname+'_dem.tif')\n",
    "    if os.path.exists(pathname+'_slope.tif'):\n",
    "        pass\n",
    "    else:\n",
    "        pr.create_slope(pathname+'_dem.tif', pathname+\"_slope.tif\",  'slope_riserun')\n",
    "    large_geom = gfh.create_geom(dem_area.bounds)\n",
    "    large_coords = dem_area.bounds\n",
    "    large_coords = [large_coords[0],large_coords[1],large_coords[2],large_coords[3]]\n",
    "    pathname = '../Data/dem/ASTGTMV003_N08W074_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists, file loaded\n",
      "file exists, file loaded\n"
     ]
    }
   ],
   "source": [
    "#loads water and road graphs for large area, are larger files\n",
    "if os.path.exists(pathname+'_graph_rl.osm'):\n",
    "    pass\n",
    "    print('file exists, file loaded')\n",
    "else:\n",
    "    G_rl = ox.graph_from_polygon(large_geom, retain_all=True, truncate_by_edge = True, custom_filter='[\"highway\"~\"motorway|trunk|primary|secondary|tertiary|unclassified\"]')\n",
    "    ox.io.save_graphml(G_rl, filepath=pathname+'_graph_rl.osm', encoding='utf-8')\n",
    "    print('file created')\n",
    "\n",
    "if os.path.exists(pathname+'_graph_wl.osm'):\n",
    "    pass\n",
    "    print('file exists, file loaded')\n",
    "else:\n",
    "    G_wl = ox.graph_from_polygon(large_geom, retain_all=True, truncate_by_edge=True, custom_filter='[\"waterway\"~\"river|canal|tidal_channel\"]')\n",
    "    ox.io.save_graphml(G_wl, filepath=pathname+'_graph_wl.osm', encoding='utf-8')\n",
    "    print('file created')\n",
    "\n",
    "# G = nx.compose(w, r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#TODO: add commentssss\n",
    "if os.path.exists(pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "    \n",
    "    # G_combl = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l}_l.osm')\n",
    "    # G_wl = ox.io.load_graphml(filepath=pathname+'_graph_wl_v2.osm')\n",
    "    # G_rl = ox.io.load_graphml(filepath=pathname+'_graph_rl_v2.osm')\n",
    "    graph_counter_l+=1\n",
    "    pass\n",
    "else:\n",
    "    G_wl = ox.io.load_graphml(filepath=pathname+'_graph_wl.osm')\n",
    "    G_rl = ox.io.load_graphml(filepath=pathname+'_graph_rl.osm')\n",
    "\n",
    "    G_wl = ox.distance.add_edge_lengths(G_wl) #TODO: check with crs??\n",
    "    G_rl = ox.distance.add_edge_lengths(G_rl)\n",
    "\n",
    "\n",
    "\n",
    "    nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_rl)\n",
    "    nodes_w, edges_w = ox.utils_graph.graph_to_gdfs(G_wl)\n",
    "    \n",
    "    nodes_r['type'] = 'road'\n",
    "    edges_r['type'] = 'road'\n",
    "\n",
    "    nodes_w['type'] = 'water'\n",
    "    edges_w['type'] = 'water'\n",
    "    nodes_comb = pd.concat([nodes_w, nodes_r])\n",
    "    edges_comb = pd.concat([edges_w, edges_r])\n",
    "    nodes_comb.dropna(inplace=True,axis=0,how ='all')\n",
    "    nodes_comb.drop_duplicates(inplace=True)\n",
    "    #TODO: check comb graph\n",
    "\n",
    "    G_combl= ox.utils_graph.graph_from_gdfs(nodes_comb, edges_comb, {'crs': 'EPSG:4326'})\n",
    "    G_combl.remove_node(8940276086)\n",
    "    G_combl.remove_node(5144268730)\n",
    "\n",
    "    #TODO: check crs, from all graphs below\n",
    "    ox.io.save_graphml(G_combl, filepath=pathname+f'_graph_{graph_counter_l}_l.osm', encoding='utf-8')\n",
    "    graph_counter_l+=1\n",
    "\n",
    "        \n",
    "    G_rl= ox.utils_graph.graph_from_gdfs(nodes_r, edges_r, {'crs': 'EPSG:4326'})\n",
    "    ox.io.save_graphml(G_rl, filepath=pathname+'_graph_rl_v2.osm', encoding='utf-8')\n",
    "    G_wl= ox.utils_graph.graph_from_gdfs(nodes_w, edges_w, {'crs': 'EPSG:4326'})\n",
    "    ox.io.save_graphml(G_wl, filepath=pathname+'_graph_wl_v2.osm', encoding='utf-8')\n",
    "\n",
    "\n",
    "print(graph_counter_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach water and roads in large network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: plot kaartje met water blauw en weg grijs? met bbox erover heen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.634999999999991 4.821999999999999 1.2455037504961592\n"
     ]
    }
   ],
   "source": [
    "#create list of geometry seperated into n= 40 smaller bboxes, done to speed up the process\n",
    "#TODO: creeert nu 49 bboxes ergens gaat nog iets mis? Of misschien restwaardes?\n",
    "bbox_lst = gfh.clipping_bbox(large_coords, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.634999999999991 4.821999999999999 1.2455037504961592\n",
      "Number of bboxes: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_22940\\2019823246.py:7: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate =True\n",
    "\n",
    "\n",
    "if validate == True:\n",
    "    bbox = large_coords\n",
    "    fig = val.val_bbox(bbox, 40)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make into validate function\n",
    "valid=False\n",
    "if valid == True:\n",
    "    geom = gfh.create_geom(bbox_lst[8])\n",
    "    # geom = box(*bbox_lst[8])\n",
    "    G_r = ox.graph_from_polygon(geom, retain_all=True, truncate_by_edge = True, custom_filter='[\"highway\"~\"motorway|trunk|primary|secondary|tertiary|unclassified\"]')\n",
    "    print(\"contains roads\")\n",
    "    G_w = ox.graph_from_polygon(geom, retain_all=True, truncate_by_edge=True, custom_filter='[\"waterway\"~\"river|canal|tidal_channel\"]')\n",
    "    print(\"contains water\")\n",
    "\n",
    "\n",
    "    a,b,c,d = bbox_lst[8]\n",
    "\n",
    "    print(geom)\n",
    "    print(a)\n",
    "    print(bbox_lst[8])\n",
    "\n",
    "    G_split = ox.truncate.truncate_graph_bbox(G_wl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "    G_overside =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "\n",
    "    nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_r)\n",
    "    nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_overside)\n",
    "    # bbox = bbox_lst[8]\n",
    "    # print(bbox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "if testing == True:\n",
    "    graph_counter_l +=100\n",
    "    graph_counter_s +=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = False\n",
    "if validate == True:\n",
    "    count = 0\n",
    "    #list to save nodes that are not connected\n",
    "    not_connected = []\n",
    "\n",
    "    #TODO: these need to be saved as well?\n",
    "    G_wl = ox.io.load_graphml(filepath=pathname+'_graph_wl_v2.osm')\n",
    "    G_rl = ox.io.load_graphml(filepath=pathname+'_graph_rl_v2.osm')\n",
    "\n",
    "    # for bbox in tqdm(bbox_lst):\n",
    "    print(graph_counter_l)\n",
    "    #TODO: change for if testing is true\n",
    "    graph_counter_l_prev =graph_counter_l-1\n",
    "    G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    edge_lst = []\n",
    "    nodes_added = defaultdict(list)\n",
    "    #TODO: check if this works\n",
    "    a,b,c,d = bbox_lst[1]\n",
    "\n",
    "\n",
    "\n",
    "    G_split = ox.truncate.truncate_graph_bbox(G_wl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "        \n",
    "    G_overside =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "    G_wrl_cnct =  ox.truncate.truncate_graph_bbox(G_wrl_cnct, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    G_wrl_cnct = G_wrl_cnct.copy()\n",
    "    nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_overside)\n",
    "    nodes_r.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # nodes_w, edges_w = ox.utils_graph.graph_to_gdfs(G_split)\n",
    "\n",
    "    #removes all edges from road network that are in nodelist\n",
    "    #needed for overside function, to prevent nearest road from being a road that is already added through the nodelst\n",
    "    nodes_r_lst = []\n",
    "\n",
    "    for i in nodes_r.index:\n",
    "        nodes_r_lst.append({'x_start': nodes_r.loc[i]['geometry'].x, \n",
    "                            'y_start': nodes_r.loc[i]['geometry'].y,\n",
    "                            'x_goal': nodes_r.loc[i]['geometry'].x, \n",
    "                            'y_goal': nodes_r.loc[i]['geometry'].y,\n",
    "                            'u': i,\n",
    "                            'type': 'road',\n",
    "                            'goal_id': 0})\n",
    "        \n",
    "    G_split, G_wrl_cnct, nodes_edgelst, nodes_bbox = wrg.connecting(G_split, G_wrl_cnct, pathname+f'_graph_split{count}_l_valid.osm', pathname+f'_graph_temp{count}_l_valid.osm', nodes_r_lst, \"water_road\", \"water\", distance_limit = 500, waterpth = pathname+f'{count}_valid')\n",
    "    nodes_added[f'{bbox}'] = nodes_bbox\n",
    "    edge_lst.append(nodes_edgelst)\n",
    "    count+=1\n",
    "\n",
    "    for el in edge_lst:\n",
    "        for e in el:\n",
    "            try:\n",
    "                G_rl.remove_node(e)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #create subsection of water and road graph\n",
    "        \n",
    "    G_overside =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "    \n",
    "    G_wrl_cnct = G_wrl_cnct.copy()\n",
    "    nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_overside)\n",
    "\n",
    "\n",
    "    #TODO: change into wrg.connecting\n",
    "    nodes_r_lst = []\n",
    "\n",
    "    for i in nodes_r.index:\n",
    "        nodes_r_lst.append({'x_start': nodes_r.loc[i]['geometry'].x, \n",
    "                            'y_start': nodes_r.loc[i]['geometry'].y,\n",
    "                            'x_goal': nodes_r.loc[i]['geometry'].x, \n",
    "                            'y_goal': nodes_r.loc[i]['geometry'].y,\n",
    "                            'u': i,\n",
    "                            'type': 'road',\n",
    "                            'goal_id': 0})\n",
    "    G_split, G_wrl_cnct, nodes_edgelst, nodes_bbox = wrg.connecting(G_split, G_wrl_cnct, pathname+f'_graph_split{count}_s_valid2.osm', pathname+f'_graph_temp{count}_s_valid2.osm', nodes_r_lst, \"water_road_overside\", \"water\", distance_limit = 500, waterpth = pathname+f'{count}_valid')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: get_potential_overside could maybe be replaced by create_crossing\n",
    "#TODO: for some reason there is very little input?\n",
    "#eerste 18 zijn\n",
    "count=0\n",
    "\n",
    "if os.path.exists(pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "    # G_w_split = ox.io.load_graphml(filepath=pathname+'_graph_w_split.osm')\n",
    "    # G_r_split = ox.io.load_graphml(filepath=pathname+'_graph_r_split.osm')\n",
    "    # G_wrl_cnct =  ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l}_l.osm')\n",
    "    graph_counter_l+=1\n",
    "    pass\n",
    "else:\n",
    "#list to save nodes that are not connected\n",
    "    not_connected = []\n",
    "\n",
    "    #TODO: these need to be saved as well?\n",
    "    G_wl = ox.io.load_graphml(filepath=pathname+'_graph_wl_v2.osm')\n",
    "    G_rl = ox.io.load_graphml(filepath=pathname+'_graph_rl_v2.osm')\n",
    "\n",
    "    # for bbox in tqdm(bbox_lst):\n",
    "    print(graph_counter_l)\n",
    "    #TODO: change for if testing is true\n",
    "    graph_counter_l_prev =graph_counter_l-1\n",
    "    G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    edge_lst = []\n",
    "    nodes_added = defaultdict(list)\n",
    "    #TODO: check if this works\n",
    "    print('graph loaded')\n",
    "    # small_coords = [-73.10001388888889,8.5, -72.99986111111112, 8.60013888888889]\n",
    "    # a,b,c,d = small_coords\n",
    "\n",
    "    # G_wrl_cnct = ox.truncate.truncate_graph_bbox(G_wrl_cnct,d,  b, c, a, truncate_by_edge=False, retain_all=True)\n",
    "    # print('clipped')\n",
    "    # G_wl =  ox.truncate.truncate_graph_bbox(G_wl, d,  b, c, a, truncate_by_edge=False, retain_all=True)\n",
    "    # print('clipped 2')\n",
    "    # G_rl =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=False, retain_all=True)\n",
    "    # print('graph clipped')\n",
    "\n",
    "    for bbox in tqdm(bbox_lst) :\n",
    "            # if count>1:\n",
    "            #         break\n",
    "                # print(bbox)\n",
    "            a,b,c,d = bbox\n",
    "\n",
    "            print(bbox)\n",
    "            \n",
    "            water_nodes = gf.get_nodes_wth_attr(G_wrl_cnct, 'type', 'water')\n",
    "            G_wl = G_wrl_cnct.subgraph(water_nodes)\n",
    "            \n",
    "\n",
    "            try:\n",
    "                G_split = ox.truncate.truncate_graph_bbox(G_wl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "                G_overside =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "                print('split')\n",
    "            except:\n",
    "                 print(count)\n",
    "                 count+=1\n",
    "                 continue\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            G_wrl_cnct = G_wrl_cnct.copy()\n",
    "            nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_overside)\n",
    "            nodes_r.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "            # nodes_w, edges_w = ox.utils_graph.graph_to_gdfs(G_split)\n",
    "\n",
    "            #removes all edges from road network that are in nodelist\n",
    "            #needed for overside function, to prevent nearest road from being a road that is already added through the nodelst\n",
    "            nodes_r_lst = []\n",
    "\n",
    "            for i in nodes_r.index:\n",
    "                nodes_r_lst.append({'x_start': nodes_r.loc[i]['geometry'].x, \n",
    "                                    'y_start': nodes_r.loc[i]['geometry'].y,\n",
    "                                    'x_goal': nodes_r.loc[i]['geometry'].x, \n",
    "                                    'y_goal': nodes_r.loc[i]['geometry'].y,\n",
    "                                    'u': i,\n",
    "                                    'type': 'road',\n",
    "                                    'goal_id': 0})\n",
    "                \n",
    "            G_split, G_wrl_cnct, nodes_edgelst, nodes_bbox = wrg.connecting(G_split, G_wrl_cnct, pathname+f'_graph_split{count}_l.osm', pathname+f'_graph_temp{count}_l.osm', nodes_r_lst, \"water_road\", \"water\", distance_limit = 500, waterpth = pathname+f'{count}', constructing_phase=\"water_road\")\n",
    "            nodes_added[f'{bbox}'] = nodes_bbox\n",
    "            edge_lst.append(nodes_edgelst)\n",
    "            count+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open(pathname+f'_oversides.pk','wb') as f:\n",
    "        pickle.dump(nodes_added, f)\n",
    "    with open(pathname+f'_water_road.pk','wb') as f:\n",
    "        pickle.dump(edge_lst, f)\n",
    "\n",
    "\n",
    "    ox.io.save_graphml(G_split, filepath=pathname+'_graph_w_split.osm', encoding='utf-8')\n",
    "    ox.io.save_graphml(G_wrl_cnct, filepath=pathname+f'_graph_{graph_counter_l}_l.osm', encoding='utf-8')\n",
    "    \n",
    "    graph_counter_l+=1\n",
    "    G_split = None\n",
    "    G_overside = None\n",
    "    G_wrl_cnct = None\n",
    "\n",
    "\n",
    "    # G_w_split = G_split\n",
    "    # G_r_split = G_overside\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: remove graphg from files!!!\n",
    "\n",
    "if os.path.exists(pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "    # G_w_split = ox.io.load_graphml(filepath=pathname+'_graph_w_split.osm')\n",
    "    # G_r_split = ox.io.load_graphml(filepath=pathname+'_graph_r_split.osm')\n",
    "    # G_wrl_cnct =  ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l}_l.osm')\n",
    "    print(graph_counter_l)\n",
    "    graph_counter_l+=1\n",
    "    pass\n",
    "else:\n",
    "    #list to save nodes that are not connected\n",
    "    not_connected = []\n",
    "\n",
    "    # for bbox in tqdm(bbox_lst):\n",
    "    count=0\n",
    "    print(graph_counter_l, 'hi')\n",
    "    graph_counter_l_prev =graph_counter_l-1\n",
    "    G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    G_rl = ox.io.load_graphml(filepath=pathname+'_graph_rl_v2.osm')\n",
    "\n",
    "    \n",
    "    # a,b,c,d = small_coords\n",
    "\n",
    "    # G_rl =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=False, retain_all=True)\n",
    "\n",
    "    nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_wrl_cnct)\n",
    "\n",
    "\n",
    "\n",
    "    with open(pathname+f'_oversides.pk','rb') as f:\n",
    "        nodes_added = pickle.load(f)\n",
    "    with open(pathname+f'_water_road.pk','rb') as f:\n",
    "        edge_lst = pickle.load(f)\n",
    "\n",
    "    #removes nodes from roads that are already connected to water\n",
    "    for el in edge_lst:\n",
    "        for e in el:\n",
    "            try:\n",
    "                G_rl.remove_node(e)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    for bbox in tqdm(bbox_lst):\n",
    "        # if os.path.exists(pathname+f'_graph_{graph_counter_l_prev}_l.osm'):\n",
    "        #     count+=1\n",
    "            \n",
    "        #     G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "        #     continue\n",
    "\n",
    "        a,b,c,d = bbox\n",
    "\n",
    "        #create subsection of water and road graph\n",
    "        try:\n",
    "            G_split =  ox.truncate.truncate_graph_bbox(G_rl, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "            G_overside =  ox.truncate.truncate_graph_bbox(G_wrl_cnct, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        G_wrl_cnct = G_wrl_cnct.copy()\n",
    "\n",
    "        #TODO: change into wrg.connecting\n",
    "        nodes_r_lst = []\n",
    "\n",
    "        edges = gf.get_edges_wth_attr(G_overside, 'type', 'water_road')\n",
    "        print(len(edges))\n",
    "\n",
    "        nodes_added = []\n",
    "        for u,v,i in edges:\n",
    "            if G_overside.nodes[v]['type'] == 'water':\n",
    "                nodes_added.append(v)\n",
    "            if G_overside.nodes[u]['type'] == 'water' :\n",
    "                nodes_added.append(u)\n",
    "\n",
    "        for i in nodes_added:\n",
    "                nodes_r_lst.append({'x_start': nodes_r.loc[i]['geometry'].x, \n",
    "                                    'y_start': nodes_r.loc[i]['geometry'].y,\n",
    "                                    'x_goal': nodes_r.loc[i]['geometry'].x, \n",
    "                                    'y_goal': nodes_r.loc[i]['geometry'].y,\n",
    "                                    'u': i,\n",
    "                                    'type': 'road',\n",
    "                                    'goal_id': 0})\n",
    "        G_split, G_wrl_cnct, nodes_edgelst, nodes_bbox = wrg.connecting(G_split, G_wrl_cnct, pathname+f'_graph_split{count}_s.osm', pathname+f'_graph_temp{count}_s.osm', nodes_r_lst, \"water_road_overside\", \"water\", distance_limit = 500, waterpth = pathname+f'{count},  constructing_phase=\"water_road_overside\")')\n",
    "                \n",
    "        count+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ox.io.save_graphml(G_split, filepath=pathname+'_graph_w_split.osm', encoding='utf-8')\n",
    "    # ox.io.save_graphml(G_overside, filepath=pathname+'_graph_r_split.osm', encoding='utf-8')\n",
    "    ox.io.save_graphml(G_wrl_cnct, filepath=pathname+f'_graph_{graph_counter_l}_l.osm', encoding='utf-8')\n",
    "    \n",
    "    graph_counter_l+=1\n",
    "    G_split = None\n",
    "    G_overside = None\n",
    "    G_wrl_cnct = None\n",
    "\n",
    "\n",
    "    # G_w_split = G_split\n",
    "    # G_r_split = G_overside\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(graph_counter_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'road': 163059, 'water': 20950, 'water_road': 16511, 'water_road_overside': 538})\n",
      "Counter({'road': 80029, 'water': 15803, 'water_road': 2099, 'water_road_overside': 116})\n"
     ]
    }
   ],
   "source": [
    "validate = True\n",
    "if validate == True:\n",
    "    graph_counter_l_prev =2\n",
    "    G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "    #TODO: why node type water_road as well?\n",
    "    print(val.validate_edge_attr(G_wrl_cnct, 'type'))\n",
    "    print(val.validate_node_attr(G_wrl_cnct, 'type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'road': 162814, 'water': 20955, 'water_road': 16511})\n",
      "Counter({'road': 79788, 'water': 15840, 'water_road': 2099})\n"
     ]
    }
   ],
   "source": [
    "validate = True\n",
    "if validate == True:\n",
    "    \n",
    "    graph_counter_l_prev =1\n",
    "    G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "    #TODO: why node type water_road as well?\n",
    "    print(val.validate_edge_attr(G_wrl_cnct, 'type'))\n",
    "    print(val.validate_node_attr(G_wrl_cnct, 'type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(pathname+f'_nc'):\n",
    "#         with open(pathname+f'_nc','rb') as f:\n",
    "#             not_connected = pickle.load(f)\n",
    "# else:\n",
    "#     with open(pathname+f'_nc','wb') as f:\n",
    "#         pickle.dump(not_connected, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.compose(G_w_split, G_r_split)\n",
    "# nodes, edges = ox.utils_graph.graph_to_gdfs(G)\n",
    "# nodes_edges = pd.concat([nodes.reset_index(), edges.reset_index()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "    # G_w_split = ox.io.load_graphml(filepath=pathname+'_graph_w_split.osm')\n",
    "    # G_r_split = ox.io.load_graphml(filepath=pathname+'_graph_r_split.osm')\n",
    "    # G_wrl_cnct =  ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l}_l.osm')\n",
    "    print(graph_counter_l)\n",
    "    graph_counter_l+=1\n",
    "    pass\n",
    "else:\n",
    "    graph_counter_l_prev =graph_counter_l - 1\n",
    "    G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    G_wrl_un = G_wrl_cnct.to_undirected(reciprocal=False, as_view=False)\n",
    "    a = [c for c in sorted(nx.connected_components(G_wrl_un), key=len, reverse=True)]\n",
    "    S0 = G_wrl_cnct.subgraph(a[0]).copy()\n",
    "    ox.io.save_graphml(S0, filepath=pathname+f'_graph_{graph_counter_l}_l.osm', encoding='utf-8')\n",
    "    graph_counter_l+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test == True:\n",
    "    pathname = '../Data/dem2/ASTGTMV003_N08W074'\n",
    "\n",
    "dem_area, dem_array_area = gfh.read_rast_rasterio(pathname+'_dem.tif')\n",
    "if os.path.exists(pathname+'_slope.tif'):\n",
    "    pass\n",
    "else:\n",
    "    pr.create_slope(pathname+'_dem.tif', pathname+\"_slope.tif\",  'slope_riserun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_area = gfh.create_geom(dem_area.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(left=-74.0001388888889, bottom=7.999861111111111, right=-72.99986111111112, top=9.00013888888889)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_area.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoj = shapely.to_geojson(large_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myfile.geojson', 'w') as f:\n",
    "   json.dump(geoj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test == True:\n",
    "    geom_small = gfh.create_geom(rio.coords.BoundingBox(dem_area.bounds[0],dem_area.bounds[1],dem_area.bounds[0]+0.4, dem_area.bounds[1]+0.4))\n",
    "    raster = rxr.open_rasterio(pathname+'_dem.tif')\n",
    "    pathname = '../Data/dem/ASTGTMV003_N08W074'\n",
    "    clipped_raster = raster.rio.clip([geom_small])\n",
    "    \n",
    "    # Save clipped raster\n",
    "    path_to_tif_file = pathname + \"_clipped_test_dem.tif\"\n",
    "\n",
    "    clipped_raster.rio.to_raster(path_to_tif_file)\n",
    "    pathname = '../Data/dem/ASTGTMV003_N08W074_clipped_test'\n",
    "    pathname+'_dem.tif'\n",
    "\n",
    "    dem_area, dem_array_area = gfh.read_rast_rasterio(pathname+'_dem.tif')\n",
    "    if os.path.exists(pathname+'_slope.tif'):\n",
    "        pass\n",
    "    else:\n",
    "        pr.create_slope(pathname+'_dem.tif', pathname+\"_slope.tif\",  'slope_riserun')\n",
    "\n",
    "    geom_area=geom_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-74.0001388888889, 7.999861111111111, -72.99986111111112, 9.00013888888889)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom_area.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steepness: https://upcommons.upc.edu/handle/2117/369636, max 0.5\n",
    "\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1456186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if valid == True:\n",
    "    nodesc, datac = zip(*G_wrl_cnct.nodes(data=True))\n",
    "    gdf_nodes = gpd.GeoDataFrame(datac, index=nodesc)\n",
    "    gdf_nodes.loc[gdf_nodes.y.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check how this happened??\n",
    "# gdf_nodes.loc[[5144268730]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = dem_area.bounds\n",
    "graph_counter_l_prev = graph_counter_l-1\n",
    "G_wrl_cnct = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "G_raster = ox.truncate.truncate_graph_bbox(G_wrl_cnct, d,  b, c, a, truncate_by_edge=False, retain_all=True)\n",
    "\n",
    "nodes, edges = ox.utils_graph.graph_to_gdfs(G_raster)\n",
    "nodes_edges = pd.concat([nodes.reset_index(), edges.reset_index()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "#TODO: as all roads and water are in one graph: only needs to be applied once?\n",
    "#TODO: correct file names\n",
    "\n",
    "#Creates a new raster where the roads and waterways are masked as 1 \n",
    "if os.path.exists(pathname+'_rasterized_river_2.tif'):\n",
    "    print('file already exists')\n",
    "    pass\n",
    "else:\n",
    "    pr.gdf_to_rast(dem_array_area.shape, nodes_edges, pathname + '_rasterized_river_2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a slope raster in degrees\n",
    "if os.path.exists(pathname+'_slope_degrees.tif'):\n",
    "    pass\n",
    "else:\n",
    "    pr.create_slope(pathname+'_dem.tif', pathname+\"_slope_degrees.tif\",  'slope_degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "#Combines the slope and road/waterway rasters\n",
    "if os.path.exists(pathname+'_slope_roads.tif'):\n",
    "    print('file already exists')\n",
    "    pass\n",
    "else:\n",
    "    arr_masked = pr.mask_xr(pathname + '_rasterized_river_2.tif', pathname + '_slope_degrees.tif', 1, 300, align=True)\n",
    "    \n",
    "        # Save clipped raster\n",
    "    path_to_tif_file = pathname + \"_slope_roads.tif\"\n",
    "\n",
    "    # # Write the data to a new geotiff file\n",
    "    # with open(path_to_tif_file, 'w') as outfile:\n",
    "    arr_masked.rio.to_raster(path_to_tif_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "#zoooo doen:\n",
    "#TODO: grenswaarde 40, want literatuur zegt 50, maaar aangezien resolutie van 30 meter, 40\n",
    "#bestand verwijderen en dan opniewus \n",
    "#meren eruit halen\n",
    "#dan dingen toevoegen tralalallalal\n",
    "\n",
    "if os.path.exists(pathname+'_slope_roads_limit.tif'):\n",
    "    print('file already exists')\n",
    "    pass\n",
    "else:\n",
    "    #TODO: waarom hier align false? Al dezelfde grootte? Of andere functie? groter dan vs isin\n",
    "    arr_masked = pr.mask_xr(pathname + '_slope_degrees.tif', pathname + '_slope_roads.tif', 40, 1000, align=False)\n",
    "        # Save clipped raster\n",
    "    path_to_tif_file = pathname + \"_slope_roads_limit.tif\"\n",
    "\n",
    "    # # Write the data to a new geotiff file\n",
    "    # with open(path_to_tif_file, 'w') as outfile:\n",
    "    arr_masked.rio.to_raster(path_to_tif_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "#TODO: check if this makes sense?\n",
    "\n",
    "if os.path.exists(pathname+'_slope_final.tif'):\n",
    "    print('file already exists')\n",
    "    pass\n",
    "else:\n",
    "    #TODO: check if everything is loaded correctly\n",
    "    waters_comb = ox.geometries.geometries_from_polygon(geom_area, tags={\"water\":\"lake\"})\n",
    "    waters_comb_clipped = waters_comb.clip(geom_area)\n",
    "    pr.gdf_to_rast(dem_array_area.shape, waters_comb_clipped, pathname+'_rasterized_lakes2.tif')\n",
    "\n",
    "    arr_masked = pr.mask_xr(pathname + '_rasterized_lakes2.tif', pathname + '_slope_roads_limit.tif', 1, 1000, align=True)\n",
    "        # Save clipped raster\n",
    "    path_to_tif_file = pathname + \"_slope_final.tif\"\n",
    "\n",
    "    # # Write the data to a new geotiff file\n",
    "    # with open(path_to_tif_file, 'w') as outfile:\n",
    "    arr_masked.rio.to_raster(path_to_tif_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add airports and other nodes to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-74.0001388888889, 7.999861111111111, -72.99986111111112, 9.00013888888889)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom_area.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pathname+f'_airstrips'):\n",
    "        with open(pathname+f'_airstrips','rb') as f:\n",
    "            airstrips = pickle.load(f)\n",
    "else:\n",
    "    a = ox.geometries.geometries_from_polygon(geom_area, tags={\"aeroway\":\"runway\"})\n",
    "    a = a[(a.source != 'ourairports.com') & (a.surface != \"asphalt\") ]\n",
    "\n",
    "    a ['geometry_points'] = [Point(j.geometry.coords[0]) for i,j in a.iterrows()]\n",
    "    airstrips = list(a.geometry_points)\n",
    "    # airstrips = set(airstrips)\n",
    "    with open(pathname+f'_airstrips','wb') as f:\n",
    "        pickle.dump(airstrips, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "G= G_raster\n",
    "#TODO: for some reason does not work in external file...\n",
    "#finds paths to road/waterway from airstrip\n",
    "airport_paths = cn.pathfinding(G, pathname+f'_airstrips_list_v2', airstrips, pathname+'_slope_final.tif', 300, 'airstrip',  [1000])\n",
    "\n",
    "#4 minuten voor 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "file loaded\n"
     ]
    }
   ],
   "source": [
    "graph_counter_l_prev = graph_counter_l-1\n",
    "graph_counter_s_prev = graph_counter_s-1\n",
    "print(graph_counter_s, graph_counter_l)\n",
    "\n",
    "\n",
    "\n",
    "G_append = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "G = G_raster\n",
    "\n",
    "#TODO: check if it works, not sure it adds the thing?\n",
    "#connects airstrip to graph\n",
    "#TODO: TODO: TODO: check if edge from small graph is same as edge from large graph in geometry?\n",
    "G_airports_small, G_airports_large = wrg.connecting(G, G_append, pathname+f'_graph_{graph_counter_s}_s.osm', pathname+f'_graph_{graph_counter_l}_l.osm', airport_paths, \"airstrip_connect\", \"new node\",  constructing_phase=\"airstr_small\")\n",
    "graph_counter_l+=1\n",
    "graph_counter_s+=1\n",
    "\n",
    "G_airports_small, G_airports_large = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = False\n",
    "if validate == True:\n",
    "    #TODO: why node type water_road as well?\n",
    "    print(val.validate_edge_attr(G_airports_large, 'type'))\n",
    "    print(val.validate_node_attr(G_airports_large, 'type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: apply the general fuctions\n",
    "#TODO: load fields\n",
    "#TODO: make fields file\n",
    "\n",
    "if os.path.exists(pathname+f'_fields_list'):\n",
    "        with open(pathname+f'_fields_list','rb') as f:\n",
    "            fields_all = pickle.load(f)\n",
    "else:\n",
    "    with open(f'fields_final.pkl','rb') as f:\n",
    "        fields = pickle.load(f)\n",
    "    \n",
    "    fields_geom = [Point(x,y) for  x,y in fields]\n",
    "\n",
    "    \n",
    "    fields_split = np.array_split(fields_geom, 33)\n",
    "        \n",
    "    count=0\n",
    "    fields_all = []\n",
    "\n",
    "    for field in tqdm(fields_split):\n",
    "\n",
    "        G = G_raster\n",
    "        field_paths = cn.pathfinding(G, pathname+f'_fields{count}', field, pathname+'_slope_final.tif', 300, 'field',  [1000])\n",
    "\n",
    "        fields_all.extend(field_paths)\n",
    "\n",
    "        count+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open(pathname+f'_fields_list','wb') as f:\n",
    "            pickle.dump(fields_all, f)\n",
    "\n",
    "#214 min 15*14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "file loaded\n"
     ]
    }
   ],
   "source": [
    "#adds labnodes to graph\n",
    "#adds labnodes to graph\n",
    "graph_counter_l_prev = graph_counter_l-1\n",
    "graph_counter_s_prev = graph_counter_s-1\n",
    "print(graph_counter_s, graph_counter_l)\n",
    "\n",
    "\n",
    "G_append = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "G = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_s_prev}_s.osm')\n",
    "#connects airstrip to graph\n",
    "#TODO: change file names before trying to fix the error \n",
    "G_fields_small, G_fields_large = wrg.connecting(G, G_append, pathname+f'_graph_{graph_counter_s}_s.osm', pathname+f'_graph_{graph_counter_l}_l.osm', fields_all, \"field_connect\", \"new node\", constructing_phase=\"fields\")\n",
    "\n",
    "graph_counter_l+=1\n",
    "graph_counter_s+=1\n",
    "#TODO: key errors? 592341882\n",
    "#18 min 203 fields\n",
    "\n",
    "G_fields_small, G_fields_large = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = False\n",
    "if validate == True:\n",
    "    #TODO: why node type water_road as well?\n",
    "    print(val.validate_edge_attr(G_airports_large, 'type'))\n",
    "    print(val.validate_node_attr(G_airports_large, 'type'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      osmid                         geometry             x              y\n",
      "0         0  POINT (-8228398.437 899995.213) -8.228398e+06  899995.212929\n",
      "1         1  POINT (-8220146.486 900072.032) -8.220146e+06  900072.032230\n",
      "2         2  POINT (-8237589.863 893621.013) -8.237590e+06  893621.012621\n",
      "3         3  POINT (-8227555.739 893966.675) -8.227556e+06  893966.675151\n",
      "4         4  POINT (-8225825.841 893649.818) -8.225826e+06  893649.817732\n",
      "...     ...                              ...           ...            ...\n",
      "2966   2966  POINT (-8130887.256 999433.416) -8.130887e+06  999433.415883\n",
      "2967   2967  POINT (-8130413.462 998740.208) -8.130413e+06  998740.207727\n",
      "2968   2968  POINT (-8128465.012 999153.589) -8.128465e+06  999153.589473\n",
      "2969   2969  POINT (-8127597.101 998701.754) -8.127597e+06  998701.753823\n",
      "2970   2970  POINT (-8128474.507 998051.808) -8.128475e+06  998051.807659\n",
      "\n",
      "[2971 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_22940\\2511381690.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df['edge'][0] = (0, lab_df.index[-1])\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(pathname+f'_laboratories'):\n",
    "        with open(pathname+f'_laboratories','rb') as f:\n",
    "            labs_selected = pickle.load(f)\n",
    "            print('file loaded')\n",
    "else:\n",
    "    #TODO: change directory\n",
    "    #TODO: maybe do the first part only once and the other stuff in the pipeline\n",
    "     #TODO: change directory\n",
    "    #TODO: maybe do the first part only once and the other stuff in the pipeline\n",
    "    with open(f'C:/Users/hanna/Documents/GitHub/msc_thesis/fastercnn-pytorch-training-pipeline/data/tiles_128_bbox/boxes_dct','rb') as f:\n",
    "        lab_dct = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    nw_pth = \"C:/Users/hanna/Documents/GitHub/msc_thesis/fastercnn-pytorch-training-pipeline/data/tiles_128/\"        \n",
    "    laboratories = []\n",
    "    for name in lab_dct.keys():\n",
    "        raster = rxr.open_rasterio(nw_pth+f'{name}.tif')\n",
    "        # ras_area, ras_arr_area = gfh.read_rast_rasterio(nw_pth+f'{name}.tif')\n",
    "        raster2 = raster.rio.reproject(\"EPSG:4326\")\n",
    "        bbox = lab_dct[name]\n",
    "        xmin, ymin, xmax, ymax = np.round(bbox)\n",
    "        x = raster2[0,ymin,xmin].coords['x'].values\n",
    "        y = raster2[0,ymin,xmin].coords['y'].values\n",
    "        #TODO: check if contains works correctly with epsg 4326\n",
    "        if geom_area.contains(Point(x,y)):\n",
    "            laboratories.append(Point(x,y))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "    #as there are too many labs, nearby labs get consolidated into one lab?\n",
    "\n",
    "    lab_df = GeoDataFrame(geometry = laboratories, crs='EPSG:4326')\n",
    "    lab_df.reset_index(names = \"osmid\", inplace=True)\n",
    "    lab_df['geometry'] = lab_df['geometry'].to_crs('3857')\n",
    "    lab_df['x'] = [row['geometry'].x for i, row in lab_df.iterrows()]\n",
    "    lab_df['y'] = [row['geometry'].y for i, row in lab_df.iterrows()]\n",
    "    edges_lab_df = GeoDataFrame(columns = ['geometry', 'osmid', 'u', 'v'], crs='3857')\n",
    "\n",
    "    print(lab_df)\n",
    "\n",
    "    lab_df['edge']=[(i, i-1) for i in lab_df.index]\n",
    "    lab_df['edge'][0] = (0, lab_df.index[-1])\n",
    "    labs_G = ox.utils_graph.graph_from_gdfs(lab_df, edges_lab_df)\n",
    "    L_connecting = lab_df.edge.to_list()\n",
    "    labs_G.add_edges_from(L_connecting)\n",
    "\n",
    "\n",
    "    #tolerance=5, then consolidate units within 10 meters\n",
    "    #neemt het midden? kan zijn dat het daardooreen rare plek is?\n",
    "    #TODO: fix that it chooses one or the other\n",
    "    #TODO: check if this is correct, as i forgot to save it\n",
    "\n",
    "    #nu 2000 meter beetje veel?\n",
    "    labs_G_cons = ox.simplification.consolidate_intersections(labs_G, tolerance=250, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "\n",
    "\n",
    "    labs_selected = []\n",
    "    lab_df2 = GeoDataFrame(geometry = laboratories, crs='3857')\n",
    "    lab_df2.reset_index(names = \"osmid\", inplace=True)\n",
    "    node_types = nx.get_node_attributes(labs_G_cons, 'osmid_original')\n",
    "    lab_df['geometry'] = lab_df['geometry'].to_crs('EPSG:4326')\n",
    "\n",
    "    for key in node_types.keys():\n",
    "        lab = node_types[key]\n",
    "        try:\n",
    "            # print(lab)\n",
    "            lab = eval(lab)[0]\n",
    "            # print(lab)\n",
    "            labs_selected.append(lab_df.loc[lab]['geometry'])\n",
    "        except:\n",
    "            labs_selected.append(lab_df.loc[lab]['geometry'])\n",
    "\n",
    "    with open(pathname+f'_laboratories','wb') as f:\n",
    "            pickle.dump(labs_selected, f)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: maybe remove? splitting up per section is only useful for graph and not for pathfinding, could still maybe be used for next step\n",
    "\n",
    "\n",
    "# lab_dct =defaultdict(list)\n",
    "# for lab in laboratories:\n",
    "#     added = False\n",
    "#     for bbox in bbox_lst:\n",
    "#         # print(bbox)\n",
    "#         geom = box(*bbox)\n",
    "#         if geom.contains(lab):\n",
    "#             lab_dct[f'{bbox}'].append(lab)\n",
    "#             added = True\n",
    "#     if added == False:\n",
    "#         # print(lab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "#TODO: check this???\n",
    "laboratories_split = np.array_split(labs_selected, 33)\n",
    "lab17 = laboratories_split[17]\n",
    "# laboratories_split[17] = np.delete(lab17, 5)\n",
    "print(len(laboratories_split[17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n"
     ]
    }
   ],
   "source": [
    "print(graph_counter_l, graph_counter_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: tile it?\n",
    "if os.path.exists(pathname+f'_laboratories_paths'):\n",
    "        with open(pathname+f'_laboratories_paths','rb') as f:\n",
    "            labnodes_all = pickle.load(f)\n",
    "else:\n",
    "    \n",
    "    count=0\n",
    "    labnodes_all = []\n",
    "\n",
    "    for laboratory in tqdm(laboratories_split):\n",
    "\n",
    "        G= G_raster\n",
    "        laboratory_paths = cn.pathfinding(G, pathname+f'_laboratories{count}', laboratory, pathname+'_slope_final.tif', 300, 'laboratory',  [1000])\n",
    "\n",
    "        labnodes_all.extend(laboratory_paths)\n",
    "\n",
    "        count+=1\n",
    "    \n",
    "    with open(pathname+f'_laboratories_paths','wb') as f:\n",
    "            pickle.dump(labnodes_all, f)\n",
    "\n",
    "#eentje van 15 duurt 36 min\n",
    "#totaal voor ongeveer 13*15 3,5 uur\n",
    "\n",
    "#gemiddeld 2 uur per 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 6\n",
      "file loaded\n"
     ]
    }
   ],
   "source": [
    "graph_counter_l_prev = graph_counter_l-1\n",
    "graph_counter_s_prev = graph_counter_s-1\n",
    "print(graph_counter_s, graph_counter_l)\n",
    "\n",
    "\n",
    "\n",
    "G_append = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "G = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_s_prev}_s.osm')\n",
    "\n",
    "\n",
    "#connects airstrip to graph\n",
    "G_labs_small, G_labs_large = wrg.connecting(G, G_append, pathname+f'_graph_{graph_counter_s}_s.osm', pathname+f'_graph_{graph_counter_l}_l.osm', labnodes_all, \"lab_connect\", \"new node\",constructing_phase=\"fields\")\n",
    "#TODO: key errors?\n",
    "graph_counter_l+=1\n",
    "graph_counter_s+=1\n",
    "\n",
    "G_labs_small, G_labs_large = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "valid = False\n",
    "if valid == True:\n",
    "    graph_counter_l_prev = graph_counter_l -1\n",
    "    G_append = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "\n",
    "    node_types = nx.get_node_attributes(G_append, \"type\")\n",
    "\n",
    "    res = Counter(node_types.values())\n",
    "\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and connect airstrips over larger area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pathname+f'_airstrips_large_v2'):\n",
    "        with open(pathname+f'_airstrips_large_v2','rb') as f:\n",
    "            airstrips_large = pickle.load(f)\n",
    "else:\n",
    "    airstr = ox.geometries.geometries_from_polygon(large_geom, tags={\"aeroway\":\"runway\"})\n",
    "    a = airstr[(airstr.source != 'ourairports.com') & (airstr.surface != \"asphalt\")]\n",
    "    #TODO: check if it still works without this filter, as this filter is not applied in previous airstrips adding:\n",
    "     #& (airstr.geometry.geom_type == 'LineString') ]\n",
    "    \n",
    "    #TODO: check if X and  and y are correct\n",
    "\n",
    "    a ['geometry_points'] = [Point(j.geometry.coords[0]) for i,j in a.iterrows()]\n",
    "    # airstrips_large = list(a.geometry_points)\n",
    "    # airstrips_large = set(airstrips_large)-set(airstrips)\n",
    "    #TODO: remove duplicate airstrips \n",
    "    airstrips_large = a\n",
    "    with open(pathname+f'_airstrips_large_v2','wb') as f:\n",
    "        pickle.dump(airstrips_large, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "airstrips_large2 = airstrips_large.loc[\"way\"].copy()\n",
    "airstrips_large2['connect_id'] = [int(abs(row['geometry'].coords[0][0]+ row['geometry'].coords[0][1])*1e6) for i, row in airstrips_large2.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "airstr_dct = defaultdict(list)\n",
    "\n",
    "for bbox in  bbox_lst:\n",
    "    bbox_geom = gfh.create_geom(bbox)       \n",
    "    for i, row  in airstrips_large2.iterrows():\n",
    "        if contains(bbox_geom, Point(row['geometry'].coords[0])):\n",
    "            airstr_dct[f'{bbox}'].append({'x_start': row['geometry'].coords[0][0], \n",
    "                                'y_start': row['geometry'].coords[0][1],\n",
    "                                'x_goal': row['geometry'].coords[0][0], \n",
    "                                'y_goal': row['geometry'].coords[0][1],\n",
    "                                'u': i,\n",
    "                                'type': 'airstrip',\n",
    "                                'goal_id': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "file loaded, 7\n"
     ]
    }
   ],
   "source": [
    "#TODO: get_potential_overside could maybe be replaced by create_crossing\n",
    "\n",
    "\n",
    "if os.path.exists( pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "    print('hi')\n",
    "    print(f'file loaded, {graph_counter_l}')\n",
    "    graph_counter_l+=1\n",
    "    pass\n",
    "else:\n",
    "    #list to save nodes that are not connected\n",
    "    not_connected = []\n",
    "\n",
    "    #TODO: change into fields, once fields is fixed\n",
    "    graph_counter_l_prev = graph_counter_l-1\n",
    "    G_combl_a = ox.io.load_graphml(filepath=pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    count=0\n",
    "\n",
    "    for key in tqdm(airstr_dct.keys()):\n",
    "        print(key)\n",
    "        bbox=eval(key)\n",
    "        a,b,c,d = bbox\n",
    "        try:\n",
    "            G = ox.truncate.truncate_graph_bbox(G_combl_a, d,  b, c, a, truncate_by_edge=True, retain_all=True)\n",
    "        except:\n",
    "            continue\n",
    "        G_append = G_combl_a.copy()\n",
    "\n",
    "\n",
    "        #create subsection of water and road graph\n",
    "        \n",
    "\n",
    "        # nodes_r, edges_r = ox.utils_graph.graph_to_gdfs(G_overside)\n",
    "        # nodes_w, edges_w = ox.utils_graph.graph_to_gdfs(G_split)\n",
    "\n",
    "        #removes all edges from road network that are in nodelist\n",
    "        #needed for overside function, to prevent nearest road from being a road that is already added through the nodelst\n",
    "        #TODO: check input of fields, make sure this input is the same\n",
    "        airstrips_all = airstr_dct[key]\n",
    "      \n",
    "\n",
    "        #connects airstrip to graph\n",
    "        G_airstr_small, G_combl_a = wrg.connecting(G, G_append, pathname+f'_graph_airstr_small{count}.osm', pathname+f'_G_combl_a{count}.osm', airstrips_all, \"airstrip_connect\", \"airstrip\", distance_limit =1000,constructing_phase=\"airstr_large\")\n",
    "\n",
    "        count+=1\n",
    "\n",
    "\n",
    "\n",
    "    ox.io.save_graphml(G_combl_a, filepath= pathname+f'_graph_{graph_counter_l}_l.osm', encoding='utf-8')\n",
    "    graph_counter_l+=1\n",
    "\n",
    "    G_airstr_small, G_combl_a = None,None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # for node in tqdm(nnwl):\n",
    "        # print(f'for {node} in, key: {key}')\n",
    "\n",
    "        # print(key,node,count)\n",
    "        # print(nodes_r.loc[node])\n",
    "        \n",
    "        # node_attr = nodes_r.loc[node]\n",
    "        #splits water edge and connect road node with new edge to where water edge is splitted\n",
    "        # crossing = wrg.create_crossing(G_split, node_attr.x, node_attr.y, node, \"water\", G_wrl_cnct, edge_attr = 'water_road')\n",
    "\n",
    "\n",
    "        # G_combs_a, G_combl_a = wrg.connecting(G, G_append, pathname+f'G_combl_a{count}.osm', pathname+f'G_combl_a{count}.osm', fields_all, \"airstrip_connect\", \"airstrip\")\n",
    "\n",
    "        # reduced_road_graph = G_overside.copy()\n",
    "        # reduced_road_graph.remove_nodes_from(nodelst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'road': 71948, 'water': 14756, 'laboratory': 2314, 'water_road': 2000, 'field': 926, 'airstrip': 257, 'water_road_overside': 117, 'field_connect': 3, 'airstrip_connect': 3, 'lab_connect': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "valid = True\n",
    "if valid == True:\n",
    "    graph_counter_l_prev = graph_counter_l -1\n",
    "    G_append = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "\n",
    "    node_types = nx.get_node_attributes(G_append, \"type\")\n",
    "\n",
    "    res = Counter(node_types.values())\n",
    "\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #adds transhipment nodes between airstrips\n",
    "# #TODO: check with plotting\n",
    "# #TODO: load graph\n",
    "# #TODO: nodes are added that are not in graph?\n",
    "# #connects airstrips\n",
    "# if os.path.exists( pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "#     print(f'file loaded {graph_counter_l}')\n",
    "#     graph_counter_l+=1\n",
    "#     pass\n",
    "# else:\n",
    "#     print(graph_counter_l)\n",
    "#     graph_counter_l_prev = graph_counter_l -1\n",
    "\n",
    "#     G_combl_a = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "#     nodesAt5 = [x for x,y in G_combl_a.nodes(data=True) if y['type']== 'airstrip']\n",
    "\n",
    "#     graph_counter_l = gf.connect_edges(G_combl_a, nodesAt5, airstrips_large2, graph_counter_l, pathname, \"transhipment_airstrip\")\n",
    "#     G_combl_a = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(graph_counter_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_counter_l_prev = graph_counter_l -1\n",
    "\n",
    "# G_combl_a = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "# nodesAt5 = [x for x,y in G_combl_a.nodes(data=True) if y['type']== 'airstrip']\n",
    "# print(len(nodesAt5))\n",
    "# # nodesAt5 = [x for x,y in G_combl_a.nodes(data=True) if y['type']== 'transhipment_airstrip']\n",
    "\n",
    "\n",
    "# graph_counter_l = gf.connect_edges(G_combl_a, nodesAt5, airstrips_large2, graph_counter_l, pathname, \"transhipment_airstrip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "valid = False\n",
    "if valid == True:\n",
    "    graph_counter_l_prev = 9\n",
    "    G_append = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "\n",
    "    node_types = nx.get_node_attributes(G_append, \"type\")\n",
    "\n",
    "    res = Counter(node_types.values())\n",
    "\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(graph_counter_l_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded, 8\n"
     ]
    }
   ],
   "source": [
    "# connects airstrips\n",
    "if os.path.exists( pathname+f'_graph_{graph_counter_l}_l.osm'):\n",
    "    print(f'file loaded, {graph_counter_l}')\n",
    "    graph_counter_l+=1\n",
    "    pass\n",
    "else:\n",
    "    print(graph_counter_l)\n",
    "\n",
    "\n",
    "    graph_counter_l_prev = graph_counter_l -1\n",
    "\n",
    "    G_combl_a = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    nodesAt5 = [x for x,y in G_combl_a.nodes(data=True) if y['type']== 'airstrip']\n",
    "\n",
    "    graph_counter_l = gf.complete_graph_from_list(G_combl_a, nodesAt5, airstrips_large2, pathname, graph_counter_l)\n",
    "    G_combl_a = None\n",
    "    print(graph_counter_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = False\n",
    "if valid == True:\n",
    "    graph_counter_l_prev = graph_counter_l -1\n",
    "    G_append = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "\n",
    "    node_types = nx.get_node_attributes(G_append, \"type\")\n",
    "\n",
    "    res = Counter(node_types.values())\n",
    "\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select ports and connect them to large network and to eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: connect rivers that end in the lake to ports? in bbox 14?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./msc_route_country_port_codes.json\")\n",
    "dict_ports = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ports_data.csv\", 'rb') as f:  # notice the r instead of w\n",
    "    ports = pd.read_csv(f, delimiter= ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ports_connections.csv\", 'rb') as f:  # notice the r instead of w\n",
    "    ports_connections = pd.read_csv(f, delimiter= ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_loc  = pd.DataFrame.from_dict(dict_ports).transpose()\n",
    "ports_loc.reset_index(inplace=True, names='port_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_merged = pd.merge(left=ports_loc, right=ports, left_on=\"port_index\",right_on=\"port\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 593 25\n"
     ]
    }
   ],
   "source": [
    "print(len(ports), len(ports_loc), len(ports_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_in_area = []\n",
    "for i,row in ports_merged.iterrows():\n",
    "    # print(row)\n",
    "    if large_geom.contains(Point(row.LocationLongitude, row.LocationLatitude)):\n",
    "        ports_in_area.append(row.port_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ports_merged['connect_id'] = 0\n",
    "ports_merged['u'] = [int(abs(row['LocationLatitude']+ row['LocationLongitude'])*1e6 ) for i,row in ports_merged.iterrows()]\n",
    "ports_merged['connect_id'] = [int(i + int(abs(row['LocationLatitude']+ row['LocationLongitude'])*1e6)) for i,row in ports_merged.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_area_df = ports_merged.loc[ports_merged['port_index'].isin(ports_in_area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_all = []\n",
    "\n",
    "for i, row in ports_area_df.iterrows():\n",
    "        ports_all.append( {'x_start': row['LocationLongitude']\t, \n",
    "                            'y_start': row['LocationLatitude'],\n",
    "                            'x_goal': row['LocationLongitude'], \n",
    "                            'y_goal': row['LocationLatitude'],\n",
    "                            'u': row['u'],\n",
    "                            'type': 'port',\n",
    "                            'goal_id': 0})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47dbff1ad89420eb8cdc8058637e2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: apply to labnodes, work out errors\n",
    "print(graph_counter_l)\n",
    "#adds labnodes to graph\n",
    "graph_counter_l_prev = graph_counter_l -1\n",
    "G_append = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "G= G_append.copy()\n",
    "\n",
    "#connects airstrip to graph\n",
    "G_ports_small, G_ports_large = wrg.connecting(G, G_append, pathname+'_graph_port_small.osm', pathname+f'_graph_{graph_counter_l}_l.osm', ports_all, \"port_connect\", \"port\", distance_limit=100000, constructing_phase=\"ports\")\n",
    "graph_counter_l+=1\n",
    "\n",
    "G_ports_small, G_ports_large = None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "valid = False\n",
    "if valid == True:\n",
    "    graph_counter_l_prev = graph_counter_l -1\n",
    "    G_append = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "    \n",
    "\n",
    "    node_types = nx.get_node_attributes(G_append, \"type\")\n",
    "\n",
    "    res = Counter(node_types.values())\n",
    "    G_append = None\n",
    "\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_outside_area = ports_merged.loc[~ports_merged['port_index'].isin(ports_in_area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_index</th>\n",
       "      <th>PortId</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryIsoCode</th>\n",
       "      <th>LocationLatitude</th>\n",
       "      <th>LocationLongitude</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>port</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>edge_betweenness</th>\n",
       "      <th>in_degree</th>\n",
       "      <th>out_degree</th>\n",
       "      <th>sum_of_degrees</th>\n",
       "      <th>closeness</th>\n",
       "      <th>u</th>\n",
       "      <th>connect_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESALG</td>\n",
       "      <td>405</td>\n",
       "      <td>ALGECIRAS</td>\n",
       "      <td>ESALG</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>ES</td>\n",
       "      <td>36.142538</td>\n",
       "      <td>-5.438306</td>\n",
       "      <td>0</td>\n",
       "      <td>ESALG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>30704232</td>\n",
       "      <td>30704232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEANR</td>\n",
       "      <td>481</td>\n",
       "      <td>ANTWERP</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>BE</td>\n",
       "      <td>51.322825</td>\n",
       "      <td>4.333416</td>\n",
       "      <td>1</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>36.128571</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>55656241</td>\n",
       "      <td>55656242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOCAU</td>\n",
       "      <td>517</td>\n",
       "      <td>CAUCEDO</td>\n",
       "      <td>DOCAU</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>DO</td>\n",
       "      <td>18.425165</td>\n",
       "      <td>-69.631032</td>\n",
       "      <td>7</td>\n",
       "      <td>DOCAU</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>5.592857</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>51205867</td>\n",
       "      <td>51205870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PACTB</td>\n",
       "      <td>167</td>\n",
       "      <td>CRISTOBAL</td>\n",
       "      <td>PACTB</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>PA</td>\n",
       "      <td>9.352367</td>\n",
       "      <td>-79.906628</td>\n",
       "      <td>9</td>\n",
       "      <td>PACTB</td>\n",
       "      <td>4.152381</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>70554261</td>\n",
       "      <td>70554265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRDKK</td>\n",
       "      <td>375</td>\n",
       "      <td>DUNKERQUE</td>\n",
       "      <td>FRDKK</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>FR</td>\n",
       "      <td>51.013644</td>\n",
       "      <td>2.181732</td>\n",
       "      <td>15</td>\n",
       "      <td>FRDKK</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>53195375</td>\n",
       "      <td>53195380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEHAM</td>\n",
       "      <td>432</td>\n",
       "      <td>HAMBURG</td>\n",
       "      <td>DEHAM</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>DE</td>\n",
       "      <td>53.530405</td>\n",
       "      <td>9.905771</td>\n",
       "      <td>14</td>\n",
       "      <td>DEHAM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.476190</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>63436176</td>\n",
       "      <td>63436182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USHOU</td>\n",
       "      <td>86</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>USHOU</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>US</td>\n",
       "      <td>29.611229</td>\n",
       "      <td>-95.0049</td>\n",
       "      <td>6</td>\n",
       "      <td>USHOU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>65393671</td>\n",
       "      <td>65393678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JMKIN</td>\n",
       "      <td>298</td>\n",
       "      <td>KINGSTON</td>\n",
       "      <td>JMKIN</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>JM</td>\n",
       "      <td>17.9837</td>\n",
       "      <td>76.8381</td>\n",
       "      <td>5</td>\n",
       "      <td>JMKIN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>94821800</td>\n",
       "      <td>94821808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRLEH</td>\n",
       "      <td>377</td>\n",
       "      <td>LE HAVRE</td>\n",
       "      <td>FRLEH</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>FR</td>\n",
       "      <td>49.467721</td>\n",
       "      <td>0.190717</td>\n",
       "      <td>16</td>\n",
       "      <td>FRLEH</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>49658438</td>\n",
       "      <td>49658448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBLGP</td>\n",
       "      <td>1375</td>\n",
       "      <td>LONDON GATEWAY PORT</td>\n",
       "      <td>GBLGP</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.505665</td>\n",
       "      <td>0.499807</td>\n",
       "      <td>19</td>\n",
       "      <td>GBLGP</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4.283333</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>52005472</td>\n",
       "      <td>52005483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USLAX</td>\n",
       "      <td>775</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>USLAX</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>US</td>\n",
       "      <td>33.728194</td>\n",
       "      <td>-118.25582</td>\n",
       "      <td>3</td>\n",
       "      <td>USLAX</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>84527626</td>\n",
       "      <td>84527638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PAMIT</td>\n",
       "      <td>1111</td>\n",
       "      <td>MANZANILLO</td>\n",
       "      <td>PAMIT</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>PA</td>\n",
       "      <td>9.362361</td>\n",
       "      <td>-79.882592</td>\n",
       "      <td>4</td>\n",
       "      <td>PAMIT</td>\n",
       "      <td>4.152381</td>\n",
       "      <td>5.283333</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>70520231</td>\n",
       "      <td>70520244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NLRTM</td>\n",
       "      <td>208</td>\n",
       "      <td>ROTTERDAM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>NETHERLANDS</td>\n",
       "      <td>NL</td>\n",
       "      <td>51.956694</td>\n",
       "      <td>4.063456</td>\n",
       "      <td>18</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>46.928571</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>56020150</td>\n",
       "      <td>56020165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GBSOU</td>\n",
       "      <td>361</td>\n",
       "      <td>SOUTHAMPTON</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>GB</td>\n",
       "      <td>50.9099</td>\n",
       "      <td>-1.4562</td>\n",
       "      <td>10</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>49453700</td>\n",
       "      <td>49453716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAPTM</td>\n",
       "      <td>1295</td>\n",
       "      <td>TANGER MED</td>\n",
       "      <td>MAPTM</td>\n",
       "      <td>MOROCCO</td>\n",
       "      <td>MA</td>\n",
       "      <td>35.893832</td>\n",
       "      <td>-5.490969</td>\n",
       "      <td>8</td>\n",
       "      <td>MAPTM</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>30402863</td>\n",
       "      <td>30402880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COTRB</td>\n",
       "      <td>1332</td>\n",
       "      <td>TURBO</td>\n",
       "      <td>COTRB</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>CO</td>\n",
       "      <td>8.097624</td>\n",
       "      <td>-76.739055</td>\n",
       "      <td>17</td>\n",
       "      <td>COTRB</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.283333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>68641431</td>\n",
       "      <td>68641449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ESVLC</td>\n",
       "      <td>401</td>\n",
       "      <td>VALENCIA</td>\n",
       "      <td>ESVLC</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>ES</td>\n",
       "      <td>39.440732</td>\n",
       "      <td>-0.323285</td>\n",
       "      <td>2</td>\n",
       "      <td>ESVLC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>39117447</td>\n",
       "      <td>39117466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NLVLI</td>\n",
       "      <td>928</td>\n",
       "      <td>VLISSINGEN</td>\n",
       "      <td>NLVLI</td>\n",
       "      <td>NETHERLANDS</td>\n",
       "      <td>NL</td>\n",
       "      <td>51.443827</td>\n",
       "      <td>3.59561</td>\n",
       "      <td>20</td>\n",
       "      <td>NLVLI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.011905</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55039437</td>\n",
       "      <td>55039457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BEZEE</td>\n",
       "      <td>589</td>\n",
       "      <td>ZEEBRUGGE</td>\n",
       "      <td>BEZEE</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>BE</td>\n",
       "      <td>51.336992</td>\n",
       "      <td>3.192726</td>\n",
       "      <td>12</td>\n",
       "      <td>BEZEE</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.426190</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>54529718</td>\n",
       "      <td>54529739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VEGUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.24756</td>\n",
       "      <td>-64.59019</td>\n",
       "      <td>22</td>\n",
       "      <td>VEGUT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>54342630</td>\n",
       "      <td>54342654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   port_index PortId         LocationName LocationCode         CountryName  \\\n",
       "0       ESALG    405            ALGECIRAS        ESALG               SPAIN   \n",
       "1       BEANR    481              ANTWERP        BEANR             BELGIUM   \n",
       "3       DOCAU    517              CAUCEDO        DOCAU  DOMINICAN REPUBLIC   \n",
       "4       PACTB    167            CRISTOBAL        PACTB              PANAMA   \n",
       "5       FRDKK    375            DUNKERQUE        FRDKK              FRANCE   \n",
       "6       DEHAM    432              HAMBURG        DEHAM             GERMANY   \n",
       "7       USHOU     86              HOUSTON        USHOU       UNITED STATES   \n",
       "8       JMKIN    298             KINGSTON        JMKIN             JAMAICA   \n",
       "10      FRLEH    377             LE HAVRE        FRLEH              FRANCE   \n",
       "11      GBLGP   1375  LONDON GATEWAY PORT        GBLGP      UNITED KINGDOM   \n",
       "12      USLAX    775          LOS ANGELES        USLAX       UNITED STATES   \n",
       "13      PAMIT   1111           MANZANILLO        PAMIT              PANAMA   \n",
       "15      NLRTM    208            ROTTERDAM        NLRTM         NETHERLANDS   \n",
       "16      GBSOU    361          SOUTHAMPTON        GBSOU      UNITED KINGDOM   \n",
       "17      MAPTM   1295           TANGER MED        MAPTM             MOROCCO   \n",
       "18      COTRB   1332                TURBO        COTRB            COLOMBIA   \n",
       "19      ESVLC    401             VALENCIA        ESVLC               SPAIN   \n",
       "20      NLVLI    928           VLISSINGEN        NLVLI         NETHERLANDS   \n",
       "21      BEZEE    589            ZEEBRUGGE        BEZEE             BELGIUM   \n",
       "24      VEGUT    NaN                  NaN          NaN                 NaN   \n",
       "\n",
       "   CountryIsoCode LocationLatitude LocationLongitude  Unnamed: 0   port  \\\n",
       "0              ES        36.142538         -5.438306           0  ESALG   \n",
       "1              BE        51.322825          4.333416           1  BEANR   \n",
       "3              DO        18.425165        -69.631032           7  DOCAU   \n",
       "4              PA         9.352367        -79.906628           9  PACTB   \n",
       "5              FR        51.013644          2.181732          15  FRDKK   \n",
       "6              DE        53.530405          9.905771          14  DEHAM   \n",
       "7              US        29.611229          -95.0049           6  USHOU   \n",
       "8              JM          17.9837           76.8381           5  JMKIN   \n",
       "10             FR        49.467721          0.190717          16  FRLEH   \n",
       "11             GB        51.505665          0.499807          19  GBLGP   \n",
       "12             US        33.728194        -118.25582           3  USLAX   \n",
       "13             PA         9.362361        -79.882592           4  PAMIT   \n",
       "15             NL        51.956694          4.063456          18  NLRTM   \n",
       "16             GB          50.9099           -1.4562          10  GBSOU   \n",
       "17             MA        35.893832         -5.490969           8  MAPTM   \n",
       "18             CO         8.097624        -76.739055          17  COTRB   \n",
       "19             ES        39.440732         -0.323285           2  ESVLC   \n",
       "20             NL        51.443827           3.59561          20  NLVLI   \n",
       "21             BE        51.336992          3.192726          12  BEZEE   \n",
       "24            NaN         10.24756         -64.59019          22  VEGUT   \n",
       "\n",
       "    betweenness  edge_betweenness  in_degree  out_degree  sum_of_degrees  \\\n",
       "0      0.000000          8.833333          3           3               3   \n",
       "1     36.128571          2.333333         18          18              18   \n",
       "3      1.950000          5.592857          8           8               8   \n",
       "4      4.152381          6.333333          8           8               8   \n",
       "5      2.033333          4.266667          7           7               7   \n",
       "6      0.000000          5.476190          3           3               3   \n",
       "7      0.000000          5.916667          3           3               3   \n",
       "8      0.250000          4.233333          5           5               5   \n",
       "10     0.200000          6.333333          5           5               5   \n",
       "11     0.900000          4.283333          7           7               7   \n",
       "12     0.000000          2.033333          2           2               2   \n",
       "13     4.152381          5.283333          8           8               8   \n",
       "15    46.928571          6.533333         19          19              19   \n",
       "16     0.000000          4.000000          4           4               4   \n",
       "17     0.250000          5.083333          5           5               5   \n",
       "18     0.400000          5.283333          5           5               5   \n",
       "19     0.000000         12.833333          4           4               4   \n",
       "20     0.000000          9.011905          3           3               3   \n",
       "21     1.200000          5.426190          7           7               7   \n",
       "24     0.000000          6.416667          2           2               2   \n",
       "\n",
       "    closeness         u  connect_id  \n",
       "0    0.533333  30704232    30704232  \n",
       "1    0.800000  55656241    55656242  \n",
       "3    0.600000  51205867    51205870  \n",
       "4    0.600000  70554261    70554265  \n",
       "5    0.585366  53195375    53195380  \n",
       "6    0.533333  63436176    63436182  \n",
       "7    0.533333  65393671    65393678  \n",
       "8    0.558140  94821800    94821808  \n",
       "10   0.558140  49658438    49658448  \n",
       "11   0.585366  52005472    52005483  \n",
       "12   0.521739  84527626    84527638  \n",
       "13   0.600000  70520231    70520244  \n",
       "15   0.827586  56020150    56020165  \n",
       "16   0.545455  49453700    49453716  \n",
       "17   0.558140  30402863    30402880  \n",
       "18   0.558140  68641431    68641449  \n",
       "19   0.545455  39117447    39117466  \n",
       "20   0.500000  55039437    55039457  \n",
       "21   0.585366  54529718    54529739  \n",
       "24   0.510638  54342630    54342654  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ports_outside_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "54529718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#TODO clean up make function\n",
    "ports_all = []\n",
    "graph_counter_l_prev = graph_counter_l -1\n",
    "G_ports_large = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "\n",
    "for i, row in ports_outside_area.iterrows():\n",
    "        G_ports_large.add_node(int(row['u']), y= row['LocationLatitude'], x= row['LocationLongitude'], type='port')\n",
    "\n",
    "\n",
    "\n",
    "# nodesAt5 = [x for x,y in G_ports_large.nodes(data=True) if y['type']== 'port']\n",
    "\n",
    "# graph_counter_l = gf.connect_edges(G_ports_large, nodesAt5, ports_merged, graph_counter_l,pathname, \"transhipment_port\")\n",
    "print(graph_counter_l)\n",
    "# G_ports_large = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "valid = False\n",
    "if valid == True:\n",
    "\n",
    "    node_types = nx.get_node_attributes(G_ports_large, \"type\")\n",
    "\n",
    "    res = Counter(node_types.values())\n",
    "\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[30704232, 65132273]\n",
      "[30704232, 53195375]\n",
      "[30704232, 56020150]\n",
      "[55656241, 39117447]\n",
      "[55656241, 70520231]\n",
      "[55656241, 94821800]\n",
      "[55656241, 65393671]\n",
      "[55656241, 51205867]\n",
      "[55656241, 30402863]\n",
      "[55656241, 70554261]\n",
      "[55656241, 49453700]\n",
      "[55656241, 65132273]\n",
      "[55656241, 54529718]\n",
      "[55656241, 62975570]\n",
      "[55656241, 63436176]\n",
      "[55656241, 53195375]\n",
      "[55656241, 49658438]\n",
      "[55656241, 68641431]\n",
      "[55656241, 56020150]\n",
      "[55656241, 52005472]\n",
      "[55656241, 55039437]\n",
      "[55656241, 56350873]\n",
      "[55656241, 57526123]\n",
      "[39117447, 30402863]\n",
      "[39117447, 65132273]\n",
      "[39117447, 56020150]\n",
      "[84527626, 65132273]\n",
      "[84527626, 56020150]\n",
      "[70520231, 94821800]\n",
      "[70520231, 65132273]\n",
      "[70520231, 68641431]\n",
      "[70520231, 56020150]\n",
      "[70520231, 56350873]\n",
      "[70520231, 57526123]\n",
      "[94821800, 51205867]\n",
      "[94821800, 65132273]\n",
      "[94821800, 56020150]\n",
      "[65393671, 65132273]\n",
      "[65393671, 56020150]\n",
      "[51205867, 49453700]\n",
      "[51205867, 65132273]\n",
      "[51205867, 54529718]\n",
      "[51205867, 62975570]\n",
      "[51205867, 56020150]\n",
      "[51205867, 52005472]\n",
      "[30402863, 65132273]\n",
      "[30402863, 53195375]\n",
      "[30402863, 56020150]\n",
      "[70554261, 65132273]\n",
      "[70554261, 54529718]\n",
      "[70554261, 68641431]\n",
      "[70554261, 56020150]\n",
      "[70554261, 56350873]\n",
      "[70554261, 57526123]\n",
      "[49453700, 65132273]\n",
      "[49453700, 56020150]\n",
      "[65132273, 54529718]\n",
      "[65132273, 62975570]\n",
      "[65132273, 63436176]\n",
      "[65132273, 53195375]\n",
      "[65132273, 49658438]\n",
      "[65132273, 68641431]\n",
      "[65132273, 56020150]\n",
      "[65132273, 52005472]\n",
      "[65132273, 63816700]\n",
      "[65132273, 54342630]\n",
      "[65132273, 56350873]\n",
      "[65132273, 57526123]\n",
      "[54529718, 53195375]\n",
      "[54529718, 56020150]\n",
      "[54529718, 52005472]\n",
      "[54529718, 56350873]\n",
      "[54529718, 57526123]\n",
      "[62975570, 68641431]\n",
      "[62975570, 56020150]\n",
      "[62975570, 52005472]\n",
      "[62975570, 55039437]\n",
      "[62975570, 56350873]\n",
      "[63436176, 56020150]\n",
      "[63436176, 56350873]\n",
      "[63436176, 57526123]\n",
      "[53195375, 49658438]\n",
      "[53195375, 56020150]\n",
      "[49658438, 56020150]\n",
      "[49658438, 52005472]\n",
      "[49658438, 56350873]\n",
      "[49658438, 57526123]\n",
      "[56020150, 52005472]\n",
      "[56020150, 55039437]\n",
      "[56020150, 56350873]\n",
      "[56020150, 57526123]\n",
      "[55039437, 56350873]\n",
      "[55039437, 57526123]\n",
      "[54342630, 56350873]\n",
      "[56350873, 57526123]\n"
     ]
    }
   ],
   "source": [
    "graph_counter_l_prev = graph_counter_l -1\n",
    "print(graph_counter_l)\n",
    "# G_ports_large_v2 = ox.io.load_graphml(filepath= pathname+f'_graph_{graph_counter_l_prev}_l.osm')\n",
    "\n",
    "\n",
    "port_edges = []\n",
    "columns = ports_connections.columns.to_list()[1:]\n",
    "\n",
    "for c in columns:\n",
    "    pc = ports_connections.loc[ports_connections[c] == 1]\n",
    "\n",
    "    pl = pc.Port.to_list()\n",
    "\n",
    "    for p in pl:\n",
    "        if (p,c) not in port_edges:\n",
    "            port_edges.append((c,p))\n",
    "\n",
    "            c_df = ports_merged.loc[ports_merged['port_index'] == c]\n",
    "            p_df =  ports_merged.loc[ports_merged['port_index'] == p]\n",
    "            p1 = c_df['u'].values[0]\n",
    "            p2 = p_df['u'].values[0]\n",
    "            x1,y1= c_df['LocationLongitude'], c_df['LocationLatitude']\n",
    "            x2,y2 = p_df['LocationLongitude'], p_df['LocationLatitude']\n",
    "            pnt1,pnt2 = Point(x1,y1),Point(x2,y2)\n",
    "            G_ports_large.add_edge(int(p1),int(p2), osmid= [int(p1),int(p2)], length =  0, geometry=LineString([pnt1, pnt2]) , type = \"sea\")\n",
    "            print([int(p1),int(p2)])\n",
    "\n",
    "ox.io.save_graphml(G_ports_large, filepath= pathname+f'_graph_{graph_counter_l}_l.osm', encoding='utf-8')\n",
    "graph_counter_l+=1\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geothings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
